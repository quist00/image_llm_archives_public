{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfba8825",
   "metadata": {},
   "source": [
    "# Generate titles, decriptions, and subjects for images in multiple steps while keeping a human in the loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df3ae7",
   "metadata": {},
   "source": [
    "## make sure virutal environment is active\n",
    "on mac:\n",
    "`source venv/bin/activate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4070fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import glob\n",
    "\n",
    "\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torchvision\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    ")\n",
    "\n",
    "# set some path stings for later use\n",
    "img_base = \"img/\"\n",
    "output_base = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982a7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a90095637e4917aba585c4b82eec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select image folder:', layout=Layout(width='70%'), options=('campus_scenes',), style=Des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert all images to standard jpg format\n",
    "\n",
    "def pre_process_images(input_dir, output_dir=None, target_width=1024, quality=85):\n",
    "    \"\"\"\n",
    "    Convert all input files in input_dir (and subfolders) to JPG with a fixed width.\n",
    "    Maintains aspect ratio for height. Saves JPGs in the same directory or output_dir.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing image files (searches subfolders).\n",
    "        output_dir (str, optional): Directory to save JPGs. If None, saves in same directory as TIFFs.\n",
    "        target_width (int): Desired width of JPGs (default: 1024 pixels).\n",
    "        quality (int): JPG quality (0-100, default: 85 for good balance of size and quality).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of (img_path, jpg_path, error) tuples for each processed file.\n",
    "    \"\"\"\n",
    "    # Ensure input directory exists\n",
    "    if not os.path.isdir(input_dir):\n",
    "        raise ValueError(f\"Input directory does not exist: {input_dir}\")\n",
    "    \n",
    "    if not output_dir:\n",
    "        output_dir = input_dir + \"_jpg\"\n",
    "    # If output_dir is specified, ensure it exists\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Find all image files recursively\n",
    "    file_set = glob.glob(os.path.join(input_dir, \"**\", \"*.[tTjJpP][iIpPnN][fFgG]*\"), recursive=True)\n",
    "    print(f\"Found {len(file_set)} files.\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for file_path in tqdm(file_set, desc=\"Preprocessing images\", unit=\"file\"):\n",
    "        try:\n",
    "            # Open image\n",
    "            with Image.open(file_path) as img:\n",
    "                # Convert to RGB \n",
    "                img = img.convert(\"RGB\")\n",
    "                \n",
    "                # Calculate proportional height\n",
    "                original_width, original_height = img.size\n",
    "                aspect_ratio = original_height / original_width\n",
    "                target_height = int(target_width * aspect_ratio)\n",
    "                \n",
    "                # Resize image\n",
    "                img = img.resize((target_width, target_height), Image.LANCZOS)\n",
    "                \n",
    "                # Save in output_dir, preserving relative path\n",
    "                rel_path = os.path.relpath(file_path, input_dir)\n",
    "                orinal_file_name = os.path.basename(file_path)\n",
    "                base_name, ext = os.path.splitext(orinal_file_name)\n",
    "                jpg_filename = base_name + \".jpg\"\n",
    "                jpg_path = os.path.join(output_dir, jpg_filename)\n",
    "                os.makedirs(os.path.dirname(jpg_path), exist_ok=True)\n",
    "\n",
    "                \n",
    "                # Save as JPG\n",
    "                img.save(jpg_path, format=\"JPEG\", quality=quality)\n",
    "                \n",
    "            results.append((orinal_file_name, file_path, jpg_path, base_name))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {file_path}: {e}\")\n",
    "            results.append((file_path, None, str(e)))\n",
    "    \n",
    "    # # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(results, columns=[\"original_file_name\",\"relative_path\",\"compressed_file_path\",\"key\"])\n",
    "\n",
    "\n",
    "    output_filename = f\"{output_dir}/compressed_files_list.csv\"\n",
    "\n",
    "    # save to CSV\n",
    "    df.to_csv(output_filename, index=False)\n",
    "\n",
    "\n",
    "# pre-process images widget\n",
    "# List only directories in the target path, excluding those ending with '_jpgs'\n",
    "folder_options = sorted([\n",
    "    f for f in os.listdir(img_base)\n",
    "    if os.path.isdir(os.path.join(img_base, f)) and not f.endswith('_jpgs')\n",
    "])\n",
    "\n",
    "folder_widget = widgets.Dropdown(\n",
    "    options=folder_options,\n",
    "    description='Select image folder:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "display(folder_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dab142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images: 100%|██████████| 3/3 [00:00<00:00,  3.38file/s]\n"
     ]
    }
   ],
   "source": [
    "# Process images\n",
    "selected_folder = os.path.join(img_base, folder_widget.value)\n",
    "pre_process_images(selected_folder, output_dir= img_base + folder_widget.value + \"_jpgs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22715ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set the project folder containing the images to be processed\n",
    "project_folder = folder_widget.value + \"_jpgs/\"\n",
    "\n",
    "# Export project_folder to a .env file for bash scripts\n",
    "with open(\"project_folder.env\", \"w\") as f:\n",
    "    f.write(f'PROJECT_FOLDER=\"{project_folder}\"\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37280afd",
   "metadata": {},
   "source": [
    "## spinup\n",
    "Create image and reconciliation services for open refine (also verifies venv is active, but no longer necessary)\n",
    "\n",
    "    bash scripts/spinup.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3f9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544d6edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8fd8b6c03642088a4caccf510cc990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For Apple ARM/MLX\n",
    "if torch.backends.mps.is_available():\n",
    "    from mlx_vlm import generate, load\n",
    "    from mlx_vlm.prompt_utils import apply_chat_template\n",
    "    from mlx_vlm.utils import load_config, load_image\n",
    "\n",
    "    model_id=\"mlx-community/Qwen2.5-VL-7B-Instruct-4bit\"\n",
    "    torch.set_default_device(\"mps:0\")\n",
    "    device = \"mps:0\"\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    model, processor = load(model_id)\n",
    "    config = model.config\n",
    "else:\n",
    "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        model_id, torch_dtype=\"auto\", device_map=\"auto\"\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    config = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ecf31",
   "metadata": {},
   "source": [
    "## Prompt Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145e927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an archivist librarian tasked with generating metadata for image sets.\"\n",
    "\n",
    "title_only_query = (\n",
    "    f\"Analyze the provided image and generate a title caption of 50 words or less. \"\n",
    "    \"Return a valid JSON string with the following fields: \"\n",
    "    \"{{\\\"title\\\": \\\"title caption you generated\\\"}}. \"\n",
    "    \"Ensure the output is a clean JSON string with double quotes around keys and string values. \"\n",
    "    \"Do not wrap the JSON in backticks, markdown, or any extra text. \"\n",
    "    \"Return only the JSON string, e.g., {{\\\"title\\\": \\\"example title caption\\\"}}.\"\n",
    ")\n",
    "\n",
    "description_only_query = (\n",
    "    \"Analyze the provided image with title \\\"{title}\\\" generate a description of 500 words or less. \"\n",
    "    \"Return a valid JSON string with the following fields: \"\n",
    "    \"{{\\\"title\\\": \\\"{title}\\\", \\\"description\\\": \\\"example description\\\"}}. \"\n",
    "    \"Ensure the output is a clean JSON string with double quotes around keys and string values. \"\n",
    "    \"Do not wrap the JSON in backticks, markdown, or any extra text. \"\n",
    "    \"Return only the JSON string, e.g., {{\\\"title\\\": \\\"{title}\\\", \\\"description\\\": \\\"example description\\\"}}.\"\n",
    ")\n",
    "\n",
    "subjects_only_query = (\n",
    "    \"Analyze the provided image with title \\\"{title}\\\" and description \\\"{description}\\\" to generate LCSH compliant subject headings. \"\n",
    "    \"Ensure the subjects are valid LCSH terms from the Library of Congress Authorities (http://authorities.loc.gov) or LC Linked Data Service (http://id.loc.gov). \"\n",
    "        \"Use only standardized LCSH terms, avoiding generic or invented terms. \"\n",
    "        \"Follow these guidelines: \"\n",
    "        \"1. Use standardized LCSH terms \"\n",
    "        \"2. Avoid invented or colloquial terms \"\n",
    "        \"3. Use hierarchical terms with qualifiers when appropriate (e.g., \\\"part 1--part 2--YYYY-\\\"). \"\n",
    "        \"4. Base subjects on the key concepts in the title and description, prioritizing semantic relevance. \"\n",
    "        \"5. Limit the number of subjects to 10 or fewer, separated by '|'. \"\n",
    "        \"Ensure the output is a clean JSON string with double quotes around keys and string values. \"\n",
    "        \"Do not wrap the JSON in backticks, markdown, or any extra text. \"\n",
    "        \"Return only the JSON string, e.g., {{\\\"subjects\\\": \\\"subject1|subject2|subject3|etc.\\\"}}. \"        \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245252b",
   "metadata": {},
   "source": [
    "## Prompt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3360c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resolve_template(template, **kwargs):\n",
    "    return template.format(**kwargs)\n",
    "\n",
    "def get_prompt(query, processor=processor, config=config, system_prompt=system_prompt, template_kwargs=None):\n",
    "    \"\"\"\n",
    "    Generate a prompt for the LLM, optionally formatting the user query with template_kwargs.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user query or template string.\n",
    "        processor: The processor for the model.\n",
    "        config: The model config.\n",
    "        system_prompt (str): The system prompt string.\n",
    "        template_kwargs (dict, optional): If provided, used to format the query string.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted prompt.\n",
    "    \"\"\"\n",
    "    if template_kwargs:\n",
    "        user_content = resolve_template(query, **template_kwargs)\n",
    "    else:\n",
    "        user_content = query\n",
    "\n",
    "    message_content = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    prompt = apply_chat_template(processor, config, message_content)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def process_path(path):\n",
    "    \"\"\"\n",
    "    Process the file path to extract the filename and make into uri.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The file path to process.\n",
    "        \n",
    "    Returns:\n",
    "        str: the uri.\n",
    "    \"\"\"\n",
    "    # uri = \"http://localhost:8000/\" + project_folder + os.path.basename(path)\n",
    "    uri = \"http://localhost:8000/\" + os.path.basename(path)\n",
    "    \n",
    "    return uri\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff68943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5634869c020472987c7ae534bf23b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Input file:', layout=Layout(width='70%'), options=('compressed_files_list.csv',), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creat input selector\n",
    "input_file_widget = widgets.Dropdown(\n",
    "    options=sorted([f for f in os.listdir(img_base + project_folder) if f.endswith(\"list.csv\")]),\n",
    "    description='Input file:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "display(input_file_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc546e58",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6281092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 3/3 [00:46<00:00, 15.41s/image]\n"
     ]
    }
   ],
   "source": [
    "# MULTI-IMAGE step 1\n",
    "TEMP = 0\n",
    "\n",
    "input_file = img_base+project_folder+input_file_widget.value\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"Found {len(df)} images.\")\n",
    "\n",
    "# Add a new column for the LLM-generated title\n",
    "df[\"title\"] = \"\"\n",
    "\n",
    "for idx, item in tqdm(enumerate(df[\"compressed_file_path\"][:]), total=len(df), desc=\"Processing images\", unit=\"image\"):\n",
    "    try:\n",
    "        img = load_image(item)\n",
    "        prompt = get_prompt(title_only_query)\n",
    "        \n",
    "        # Invoke the LLM\n",
    "        output = generate(\n",
    "            model,\n",
    "            processor,\n",
    "            prompt,\n",
    "            img,\n",
    "            max_tokens=1500,\n",
    "            temperature=TEMP,\n",
    "            verbose=False\n",
    "        )\n",
    "        json_item = json.loads(output)\n",
    "        df.at[idx, \"title\"] = json_item.get(\"title\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {item}: {e}\")\n",
    "        print(json.dumps(json_item, indent=2))\n",
    "        df.at[idx, \"title\"] = f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Generate ISO 8601 timestamp and prepend to filename\n",
    "timestamp = datetime.now().isoformat().replace(\":\", \"-\")\n",
    "timestamp = timestamp.split(\".\")[0]  # Remove milliseconds\n",
    "temp_str = str(TEMP).replace(\".\", \"-\")  # Replace \".\" with \"-\" for filename compatibility\n",
    "llm_model_short = model_id.replace('/','-').replace(\"mlx-community-\", \"\")  # Replace \":\" with \"-\" for filename compatibility\n",
    "output_filename = img_base + project_folder + f\"{timestamp}_{llm_model_short}_{temp_str}__results_mlx_Step1.csv\"\n",
    "\n",
    "# save to CSV\n",
    "df[\"image\"] =  df[\"compressed_file_path\"].map(process_path)\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be817a35",
   "metadata": {},
   "source": [
    "## Generate Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac536893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e531bc57ee74b6897ecd8593df23cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Step 2 Input:', layout=Layout(width='70%'), options=('2025-10-01T11-13-42_Qwen2.5-VL-7B-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2 widget\n",
    "input_file_widget_step2 = widgets.Dropdown(\n",
    "    options=sorted([f for f in os.listdir(img_base + project_folder) if f.endswith(\"Step1.csv\")]),\n",
    "    description='Step 2 Input:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "display(input_file_widget_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9740ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 3/3 [01:08<00:00, 22.72s/image]\n"
     ]
    }
   ],
   "source": [
    "# MULTI-IMAGE step 2\n",
    "TEMP = 0\n",
    "input_file = img_base+project_folder+input_file_widget_step2.value\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "#df = df.head(2)\n",
    "# Add a new column for the LLM-generated description\n",
    "df[\"description\"] = \"\"\n",
    "\n",
    "for idx, item in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\", unit=\"image\"):\n",
    "    try:\n",
    "        img = load_image(item[\"compressed_file_path\"])\n",
    "        prompt = get_prompt(description_only_query, template_kwargs={\"title\": item[\"title\"]})\n",
    "        \n",
    "        # Invoke the LLM\n",
    "        output = generate(\n",
    "            model,\n",
    "            processor,\n",
    "            prompt,\n",
    "            img,\n",
    "            max_tokens=1500,\n",
    "            temperature=TEMP,\n",
    "            verbose=False\n",
    "        )\n",
    "        json_item = json.loads(output)\n",
    "        #df.at[idx, \"title\"] = json_item.get(\"title\", \"\")\n",
    "        df.at[idx, \"description\"] = json_item.get(\"description\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {item}: {e}\")\n",
    "        df.at[idx, \"title\"] = f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Generate ISO 8601 timestamp and prepend to filename\n",
    "timestamp = datetime.now().isoformat().replace(\":\", \"-\")\n",
    "timestamp = timestamp.split(\".\")[0]  # Remove milliseconds\n",
    "temp_str = str(TEMP).replace(\".\", \"-\")  # Replace \".\" with \"-\" for filename compatibility\n",
    "llm_model_short = model_id.replace('/','-').replace(\"mlx-community-\", \"\")  # Replace \":\" with \"-\" for filename compatibility\n",
    "output_filename = img_base + project_folder + f\"{timestamp}_{llm_model_short}_{temp_str}__results_mlx_Step2.csv\"\n",
    "\n",
    "# save to CSV\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7184e",
   "metadata": {},
   "source": [
    "## Generate Subjects - no recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccabd790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c0402b51f5437ebfe11a0ae5ed7917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Step 3 Input:', layout=Layout(width='70%'), options=('2025-10-06T09-23-37_Qwen2.5-VL-7B-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3 widget\n",
    "input_file_widget_step3 = widgets.Dropdown(\n",
    "    options=sorted([f for f in os.listdir(img_base + project_folder) if f.endswith(\"Step2.csv\")]),\n",
    "    description='Step 3 Input:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "display(input_file_widget_step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44a125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 3/3 [01:09<00:00, 23.32s/image]\n"
     ]
    }
   ],
   "source": [
    "# MULTI-IMAGE step 3 option 1\n",
    "TEMP = 0\n",
    "\n",
    "input_file = img_base+project_folder+input_file_widget_step3.value\n",
    "# read in input\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# limit process for testing\n",
    "#df = df.head(15)\n",
    "\n",
    "# Add a new column for the LLM-generated description\n",
    "#df[\"subjects\"] = \"\"\n",
    "\n",
    "for idx, item in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\", unit=\"image\"):\n",
    "    try:\n",
    "        img = load_image(item[\"compressed_file_path\"])\n",
    "        prompt = get_prompt(subjects_only_query, template_kwargs={\"title\": item[\"title\"], \"description\": item[\"description\"]})\n",
    "        \n",
    "        # Invoke the LLM\n",
    "        output = generate(\n",
    "            model,\n",
    "            processor,\n",
    "            prompt,\n",
    "            img,\n",
    "            max_tokens=1500,\n",
    "            temperature=TEMP,\n",
    "            verbose=False\n",
    "        )\n",
    "        #print(f\"output: {output}\")\n",
    "        json_item = json.loads(output)\n",
    "        #df.at[idx, \"title\"] = json_item.get(\"title\", \"\")\n",
    "        df.at[idx, \"subjects\"] = json_item.get(\"subjects\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {item}: {e}\")\n",
    "        df.at[idx, \"subjects\"] = f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Generate ISO 8601 timestamp and prepend to filename\n",
    "timestamp = datetime.now().isoformat().replace(\":\", \"-\")\n",
    "timestamp = timestamp.split(\".\")[0]  # Remove milliseconds\n",
    "temp_str = str(TEMP).replace(\".\", \"-\")  # Replace \".\" with \"-\" for filename compatibility\n",
    "llm_model_short = model_id.replace('/','-').replace(\"mlx-community-\", \"\")  # Replace \":\" with \"-\" for filename compatibility\n",
    "output_filename = img_base + project_folder + f\"{timestamp}_{llm_model_short}_{temp_str}__results_mlx_Step3.csv\"\n",
    "\n",
    "# save to CSV\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
